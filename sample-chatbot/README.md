# 🤖 Sample Chatbot

A simple, modern chatbot built with FastAPI and OpenAI, designed for easy deployment on various platforms.

## ✨ Features

- **Modern UI**: Clean, responsive chat interface
- **Real-time Chat**: Smooth conversation experience
- **OpenAI Integration**: Powered by GPT models
- **Conversation Memory**: Maintains context during chats
- **Multi-platform Deployment**: Works on Railway, Heroku, Vercel, etc.
- **Production Ready**: Error handling, validation, and monitoring

## 🛠️ Tech Stack

- **Backend**: FastAPI (Python)
- **Frontend**: Vanilla HTML/CSS/JavaScript
- **AI**: OpenAI GPT API
- **Deployment**: Multiple platform support

## 🚀 Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API Key

### Local Development

1. **Clone and setup**:
   ```bash
   git clone <your-repo>
   cd sample-chatbot
   ./start.sh
   ```

2. **Manual setup**:
   ```bash
   # Create virtual environment
   python3 -m venv venv
   source venv/bin/activate  # On Windows: venv\\Scripts\\activate
   
   # Install dependencies
   pip install -r requirements.txt
   
   # Set environment variable
   export OPENAI_API_KEY=your_api_key_here
   
   # Run the server
   python backend/main.py
   ```

3. **Access**: Open [http://localhost:8000](http://localhost:8000)

## 🌐 Deployment Options

### Railway (Recommended)

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new/template)

1. Fork this repository
2. Connect to Railway
3. Add environment variable: `OPENAI_API_KEY`
4. Deploy automatically

**Railway Specific:**
- Uses `railway.json` for configuration
- Persistent storage support
- Custom domain support

### Heroku

```bash
# Install Heroku CLI
heroku create your-app-name
heroku config:set OPENAI_API_KEY=your_api_key
git push heroku main
```

### Vercel

1. Install Vercel CLI: `npm i -g vercel`
2. Run: `vercel`
3. Set environment variables in dashboard

### Google Cloud Run

```bash
# Build and deploy
gcloud run deploy sample-chatbot \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

## 📁 Project Structure

```
sample-chatbot/
├── backend/
│   └── main.py          # FastAPI application
├── frontend/
│   └── index.html       # Chat interface
├── requirements.txt     # Python dependencies
├── Procfile            # Heroku deployment
├── railway.json        # Railway configuration
├── start.sh           # Local development script
├── .env.example       # Environment template
└── README.md          # This file
```

## 🔧 Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | Your OpenAI API key | Yes |
| `ENVIRONMENT` | Environment mode | No |

### OpenAI Models

The chatbot uses `gpt-3.5-turbo` by default. You can change this in `backend/main.py`:

```python
response = openai.ChatCompletion.create(
    model="gpt-4",  # Change model here
    # ...
)
```

## 💬 API Endpoints

### `GET /`
Serve the main chat interface

### `POST /api/chat`
Handle chat messages

**Request**:
```json
{
  "message": "Hello, how are you?",
  "history": [
    {"role": "user", "content": "Hi"},
    {"role": "assistant", "content": "Hello! How can I help?"}
  ]
}
```

**Response**:
```json
{
  "response": "I'm doing great, thank you for asking! How can I assist you today?",
  "timestamp": "2025-10-31T05:40:49Z"
}
```

### `GET /health`
Health check endpoint

### `GET /api/models`
Get available OpenAI models

## 🎨 Customization

### UI Customization

Edit `frontend/index.html` to modify:
- Chat colors and styling
- Layout and design
- Animation effects
- Mobile responsiveness

### AI Behavior

Modify the system prompt in `backend/main.py`:

```python
{"role": "system", "content": "Your custom instructions here..."}
```

## 📊 Monitoring

### Health Check
Visit `/health` endpoint for status monitoring

### Logging
Logs are automatically generated by FastAPI. Check platform-specific log viewers.

## 🔒 Security

- Environment variables for API keys
- Input validation and sanitization
- CORS configuration for production
- Rate limiting ready (implement as needed)

## 💰 Cost Estimate

**OpenAI Costs** (approximate):
- GPT-3.5-turbo: ~$0.002 per conversation
- GPT-4: ~$0.03 per conversation
- Estimated monthly: $5-50 (depending on usage)

**Platform Costs**:
- Railway: $5-20/month
- Heroku: $7-25/month
- Vercel: Free tier available
- Google Cloud Run: Pay per request

## 🐛 Troubleshooting

### Common Issues

**"OPENAI_API_KEY not found"**:
```bash
export OPENAI_API_KEY=your_actual_key
```

**"Module not found"**:
```bash
pip install -r requirements.txt
```

**Port already in use**:
```bash
# Kill process on port 8000
lsof -ti:8000 | xargs kill -9
```

**Frontend not loading**:
- Check if `frontend/index.html` exists
- Verify static file mounting in FastAPI
- Check browser console for errors

### Debug Mode

Run with debug logging:
```bash
export ENVIRONMENT=development
python backend/main.py
```

## 📈 Performance

- **Response Time**: ~2-5 seconds (depends on OpenAI)
- **Concurrent Users**: Limited by OpenAI API rate limits
- **Memory Usage**: ~100-200MB
- **Storage**: Minimal (no database required)

## 🤝 Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## 📄 License

This project is open source and available under the [MIT License](LICENSE).

## 🆘 Support

- **Issues**: Create GitHub issues for bugs
- **Discussions**: Use GitHub Discussions for questions
- **Documentation**: Check this README and inline code comments

## 🔄 Updates

- v1.0.0: Initial release with basic chatbot functionality
- Add features via GitHub issues and pull requests

---

**Made with ❤️ using FastAPI + OpenAI**